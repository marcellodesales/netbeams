\documentclass[conference]{IEEEtran}

\usepackage{epsfig}
\usepackage{fancyvrb}
\usepackage{url}

\DefineVerbatimEnvironment%
  {code}{Verbatim}{numbers=left,numbersep=3pt,frame=lines,%
                   xleftmargin=7pt,fontsize=\footnotesize}




\begin{document}


\title{A Component-Based Sensor Network for \\ Environmental Monitoring}

\author{\authorblockN{A. Puder, T. Johnson, K. Sales, M. de Sales}
\authorblockA{San Francisco State University \\
Computer Science Department \\
1600 Holloway Avenue \\
San Francisco, CA 94132 \\
EMail: \{arno$\mid$tlj$\mid$klebers$\mid$msales\}@sfsu.edu}
\and
\authorblockN{D. Robinson}
\authorblockA{San Francisco State University \\
Romberg Tiburon Center \\
3150 Paradise Drive \\
Tiburon, CA 94920 \\
EMail: dhr@sfsu.edu}}


\maketitle
\begin{abstract}
  In this paper we describe a sensor network for environmental
  monitoring based on highly specialized, off-the-shelf sensing
  devices.  Environmental monitoring depends on the reliable
  collection of measurements from remotely deployed sensors and the
  rapid transfer of those measurements to data centers. Typically,
  sensors are deployed in out-of-the-way locations, where physical
  access is limited and connections for telemetry are poor or
  nonexistent. Maintaining the data stream from these sensors places
  demands on human resources, requiring site visits to service the
  sensors and to download data stored on internal memory.  The work
  described in this paper is a collaborative effort between the
  Computer Science Department at San Francisco State University and
  the Romberg Tiburon Center. The result of this collaboration is an
  environmental sensor network deployed in the San Francisco Bay. It
  provides means to program and interrogate sensors at the remote
  field locations and to transmit collected measurements to a remote
  database.
\end{abstract}


\section{Introduction}

A wireless sensor network consists of spatially distributed autonomous
devices using sensors to cooperatively monitor physical or
environmental conditions at different locations \cite{roemer:2004}.
Much research effort is focused on building wireless ad-hoc networks
where each sensor node participates in a multi-hop routing algorithm.
One the earliest examples of a wireless sensor network is the
SmartDust project \cite{smartdust:2001} where one objective was to
create autonomous sensing and communication in a cubic
millimeter-sized device.  While most wireless sensor networks focus on
small sensing devices such as the SmartDust mote, there exist a wide
variety of off-the-shelf commercially available sensors that are used
by environmental researchers. In contrast to the small sensing
devices, sensors for environmental monitoring are typically on the
order of one to two feet in length weighing several pounds. Our
focus is on building an end-to-end infrastructure for environmental
monitoring using specialized sensing devices.

Environmental monitoring depends on the reliable collection of
measurements from remotely deployed sensors and the rapid transfer of
those measurements to data centers. Typically, sensors are deployed in
out-of-the-way locations, where physical access is limited and
connections for telemetry are poor or nonexistent. Maintaining the
data stream from these sensors places demands on human resources,
requiring site visits to service the sensors and to download data
stored on internal memory.  Consequently, there is a lag of days to
months between the time the sensors perform the measurements and the
time the measurements become available. Advances in battery life and
anti-fouling technology have extended service cycles for field
sensors, with the unwanted result of further delaying access to
monitoring data.  In addition, the dependence on field site visits to
alter of sensor characteristics, such as sampling rate, prevents
adjustment in monitoring strategy in response to rapidly developing
events (e.g. oil spills, harmful algal blooms).

The work described in this paper is a collaborative effort between the
Computer Science Department at San Francisco State University and the
Romberg Tiburon Center (RTC), a research institute focusing on the
understanding of complex marine and estuarine environments. The result
of this collaboration is NetBEAMS (Networked Bay Environmental
Assessment Monitoring System), an environmental sensor network
deployed in the San Francisco Bay. NetBEAMS provides means to program
and interrogate sensors at the remote field locations and to transmit
collected measurements to a database, where the data is rapidly
processed, archived, and made available to potential users in near
real-time. In the following sections we give an overview of the NetBEAMS
architecture and implementation.  Section \ref{SEC_BACKGROUND}
describes a typical environmental sensor used by the RTC. Section
\ref{SEC_DSP} describes our Data Sensor Platform (DSP) that allows us
to efficiently build up an end-to-end environmental sensor network.
Section \ref{SEC_NETBEAMS} describes NetBEAMS; a practical application
of the DSP. Section \ref{SEC_CONCLUSION} concludes this paper.


\section{Background}
\label{SEC_BACKGROUND}

Environmental researchers typically use standard, off-the-shelf
sensing devices for their purposes. These sensing devices are at the
opposite end of the size spectrum of miniature sensors such as SmartDust. One such
device is the YSI 6600EDS V2 Sonde \cite{Sonde01}, a water
quality monitoring device that gathers water quality data, and
operates in fresh, sea, or polluted water. Some of the measurements
that the YSI is capable of are conductivity, temperature, chloride,
ammonium, nitrate, turbidity, and chlorophyll.  It is under 55 cm in
length, 8.9 cm in diameter, and weighs approximately 3.18 kg. It
operates at temperatures between -5 to +50 deg C and at depths up to
200 meters.  It uses 8 C-size Alkaline Batteries or External 12 VDC.
Battery life can last up to 75 days depending on sensor configuration.
The Sonde's bulkhead contains multiple pin connectors to support
sensor probes for measuring parameters as shown in Table
\ref{TAB_SONDE_MEASUREMENTS}.

\begin{table}[h]
\caption{\label{TAB_SONDE_MEASUREMENTS} YSI Sonde measurements.}
\centering
\begin{tabular}{|l||l|}
\hline
\multicolumn{1}{|c||}{\textbf{Name}} &
\multicolumn{1}{c|}{\textbf{Description}} \\ \hline \hline
\texttt{Date}    & Year/Month/Day. \\ \hline
\texttt{Time}    & Hour:Minute:Second. \\ \hline
\texttt{Temp}    & Temperature in degrees Celcius. \\ \hline
\texttt{SpCond}  & Specific Description in microSiemens
                   per centimeter. \\ \hline
\texttt{Cond}    & Conductivity in microSiemens per centimeter. \\ \hline
\texttt{Resist}  & Resistivity in Ohms $*$ centimeter. \\ \hline
\texttt{Sal}     & Salinity in parts per thousand. \\ \hline
\texttt{Press}   & Pressure in pounds per square inch relative. \\ \hline
\texttt{Depth}   & Water column in meters. \\ \hline
\texttt{pH}      & pH in standard units. \\ \hline
\texttt{phmV}    & millivolts associated with the pH reading. \\ \hline
\texttt{ODOSat}  & Dissolved oxygen in \% air saturation. \\ \hline
\texttt{ODOConc} & Dissolved oxygen in mg/L. \\ \hline
\texttt{Turbid}  & Turbidity in nephelometric turbidity units. \\ \hline
\texttt{Battery} & Total Volts remaining in batteries.  \\ \hline
\end{tabular}
\end{table}


Each probe may have multiple sensors.  A computer can interface with
the Sonde via RS-232C or SDI-12. The Sonde can be configured to
collect data samples in discrete or unnattended mode.  Discrete mode
is normally performed while a technician manages the Sonde during the
sampling process. In this mode the Sonde is usually connected via 650
MDS Display/Logger or a serial cable connected to a PC.  The sampling
frequency is usually set to a high frequency in this mode.  Unattended
mode is performed usually when the Sonde is deployed offshore or in a
remote body of water.  The sampling frequency is usually set for a
longer period of time (i.e. 5 - 15 min). The Sonde is configured via a
set of menus that can be accessed through a terminal session over
RS232. Through these menus, the Sonde can be configured to start
logging data to an internal file.  To view the data as it's being
captured, the option to show live data is chosen and the data can then
seen via a serial terminal session at each interval.

We provide these details to show that sensing devices such as the YSI
are highly specialized devices with a unit price of several thousand
dollars. These sensors are usually sparsely deployed in remote
locations that not only make their maintenance difficult, but also
access to their measurements.  Typically, the sensors are autonomous
in the sense that they can run for a certain time on battery power and
store the measurement data in internal memory. Only when the sensors
are serviced, the measurement data, which was collected since the last
servicing, is uploaded to a portable storage device. From there, the
data can be uploaded to server. This manual procedure to retrieve
sensor data is not only error prone, but also results are in a serious
time lag between the time the sensor performs the measurement and when
it becomes available for further processing. For many applications,
however, it would be beneficial to have near-realtime access to the
sensor measurement. We identify the following requirements that an
end-to-end infrastructure supporting devices such as the YSI should
offer:

\begin{itemize}
\item Allow near-realtime access to sensor measurements.
\item Allow remote servicing that include changing of configuration
  parameters as well as software upgrades.
\item Support cost-effective long distance communication link.
\item Can be deployed in remote locations in unprotected outdoor
  conditions.
\end{itemize}

In the next section we describe a software architecture that provides
a foundation to fulfill these requirements.


\section{Data Sensor Platform}
\label{SEC_DSP}

Sensor networks, especially of environmental sensors, are normally
deployed over a geographically wide area where the communication
infrastructure is not always reliable or, at least, not countinuously
available. As the sensor network grows in size and complexity
scalability, reliabilty and maintainability become critical issues.
Additional components might be added to the network, sensor
configuration might be altered, or new versions of components might be
deployed. The sensor network must be able to support such adjustments
without significant overhead for maintainers.  From system
development and integration point of view, interfaces among components
and between components and the network should be simple. Complex
interaction can be constructed on top of these simple interfaces.  In
the following we discuss how our proposed architechure addresses those
issues.

\subsection{Architecture}

Our architecture is based on a micro-kernel approach. The core
functionality is limited to a minimum and all extra services are built
as plug-and-play modules on top of the micro-kernel. With the help of
this approach we can keep the basic infrastructure compact while
allowing customization via special-purpose modules. In our terminology
we call the basic foundation the \emph{Data Sensor Platform}
(DSP). The scope of the DSP is one address space of an execution
platform. A sensor network is built from several DSPs that are linked
with each other.

Figure \ref{FIG_DSP} depicts the basic architecture of the DSP. We
refer to the plug-and-play modules as DSP Components. DSP Components
are self-contained modules that can be added and removed to a DSP
installation at runtime. The basic communication paradigm within a DSP
is a message. DSP Components can exchange messages of different types.
Actually, all interactions between DSP Components are implemented
through messages yielding simple but powerful communication
instructure.  We distinguish between \emph{Data Producers} (DP) and
\emph{Data Consumers} (DC) within the scope of a DSP. DP and DC can be
seen as roles that a DSP Component may have. It is possible for a DSP
Component to act in the role of DC and DP at the same time. Messages
in DSPs are routed based on rules. Rules can be configured statically
or dynamically. Rules for routing messages can be based on different
information: producers or consumers of the message, the message
itself, or specific configuration parameters provided externally.

\begin{figure}
\centering
\epsfig{file=dsp, width=7cm}
\caption{\label{FIG_DSP} Data Sensor Platform (DSP).}
\end{figure}

The DSP is responsible for routing messages between DPs and DCs. It is
important to note that this routing only happens within a
DSP. Following the paradigm of a micro-kernel approach, the DSP has no
notion of remote communication or sensor-specific details. All this
knowledge is embodied in special purpose DSP Components.

\subsection{DSP Components}

A DSP Component encapsulates a particular functionality. We
distinguish between those components that produce data (DP) and those
that consume data (DC). An example for a DSP Component acting in the
role of a DP is a module that interfaces with a physical sensor. Such
a module reads data from the sensor and converts the data into a
message that is forwarded to the DSP. Because this module generates
data with respect to the DSP, it is a data producer. An example for a
data consumer is a converter module that converts the internal,
DSP-specific data format to a format suitable for consumption by
external applications. One such common format used in the domain of
environmental monitoring is OpenDAP \cite{opendap01}.  Since the
converter module accepts messages from the DSP, it acts in the role of
a data consumer. Finally, a DSP Component implementing persistency is
an example of a module that acts in the roles of both data producer
and consumer. It accepts messages from the DSP and stores them in a
database. At a later time, it may act as a data producer by resending
previously stored messages.

All DSP Components need to implement the following Java interface:

\begin{code}
interface DSPComponent
{
   public String getComponentType();
   public void initComponent(...);
   public void startComponent();
   public void stopComponent();
   public void deliver(DSPMessage msg);
   // ...
}
\end{code}

By implementing the above Java interface, the resuling code
effectively becomes a DSP Component that can be deployed on a DSP at
runtime. A component is identified by its type (line 3). Only one
component of a certain type per DSP is permissible. A type identifier
must be unique across all DSP Components in a DSP.  Upon deploying a
component, an initialization function is called (line 4). Once a
component is initialized, it may be started (line 5) and stopped (line
6) multiple time. Whenever the DSP wishes to pass a message (that was
generated by some DP), it invokes the \texttt{deliver()} method (line
7). The message structure will be explained in the following section.
One important feature of the DSP is the ability to redeploy (maybe
with a new version) at runtime. This allows DSPs to be updated
remotely. This process is managed through messages sent to a special
DSP Component that is able to manage its local DSP.

\subsection{Message Structure}

Message passing is the main paradigm for exchanging information within
a DSP. After producing data, a DP wraps that data in the body
of a message, so that DC components can receive the message and
consume the data contained in the message's body. When it comes to passing
messages to a remote DSP instance, messages are serialized in XML
\cite{xml2000} and automatically deserialized for DC located in the
remote DSP. In order to serialize and deserialize DSP messages, the
DSP infrastructure uses the XML Schema standard \cite{xml-schema2004}
to generate and validate the DSP message. Figure \ref{FIG_DSP_MESSAGE}
defines the structure of a general DSP message.

\begin{figure}[!htb]
 \centering
 \epsfig{file=dsp-message, width=9cm, height=4cm}
 \caption{\label{FIG_DSP_MESSAGE} Structure of a DSP message.}
\end{figure}

The basic message structure is defined by an \texttt{AbstractMessage}
type, whose structure serves as a base schema for all different types
of messages. Any message will contain two basic attributes:
\texttt{messageID} and \texttt{ContentType}.  The former uniquely
identifies a message and the latter the data in the body of the
message. Complementary identification information such as the message
producer and consumer are located in the header of the message, which
are defined by the schema type \texttt{ComponenIdentifier}. A
\texttt{ComponentIdentifier} carries out information about the
component name and its physical host address.  Finally, the body of
the message represents the payload and may contain any data type
defined by the component developer.

Although XML schema is the de-facto standard to bind and validate XML
data to its type, the architectural infrastructure of DSP uses an XML
data binding technology \cite{xml-dbind} called JAXB \cite{xml-jaxb}.
It is used to generate a type safe API for handling in-memory object
graphs from the XML instances of DSP Messages and the content of its
data payload. Moreover, taking advantage of the data type polymorphism
of XML schema data types -- a concept borrowed from object oriented
principles -- we defined different categories of messages in order to
reflect the nature of the message content. Among those categories are
query and update messages for configuring various properties supported
by DSP Components and measurement messages that actually contain
sensor readings.

The payload of a message is itself described via an XML schema in
order to integrate it seemingly with the general message structure. A
developer of a DSP Component can define a schema that represents the
type of payload processed by that component. An example illustrating a
DSP message is given when we discuss the YSI Sonde Component.

\subsection{DSP Broker}

In order to keep the API symmetrical, the DSP is itself implemented as
a DSP Component, the so-called DSP Broker. While technically the DSP
Broker has the same API as any component, it serves a special role and
cannot be removed. When a DP sends a message, it actually
invokes the \texttt{deliver()} method of the DSP Broker. The broker is
responsible for routing the message to one or several DCs. It
distinguishes between local and remote destinations:

\begin{itemize}
\item Local delivery of messages: it uses local object reference to
  deliver the DSP message.
\item Remote delivery of messages: it uses a DSP Component marked as a
  default gateway to handle remote message delivery.
\end{itemize}

The selection of the DCs for a given message to where the broker will
deliver messages to is determined by a matcher.  The matcher is
responsible to find the possible set of DCs for a given DSP message,
and it relies on matching rules defined statically or at runtim. In
this way, a set of matching rules is defined in XML and stored at the
DSP run-time directory, where each matching rule is uniquely
identified by a rule ID and determines the following (see Figure
\ref{FIG_MATCHER_RULE}):

\begin{figure}[!htb]
 \epsfig{file=dsp-match-rule, width=9cm, height=4cm}
 \caption{\label{FIG_MATCHER_RULE} Definition of Matcher Rule.}
\end{figure}

\begin{itemize}
\item The \emph{match criteria} defines the name of the component type
  of the producer and its physical location (IP address);
\item The \emph{match target} defines the name of the component type
  of the consumer, and optionally defines a gateway component.
\end{itemize}

When analyzing the matching rules, the matcher only selects the rules
that satisfy the matching criteria and forwards them back to the
broker. Once the broker has the matching rules, it determines whether
the delivery is done directly to a component defined on the match
target, or if the message is delivered to the optional gateway. We
have defined special gateway DSP components that is used to transport
the DSP Messages, serialized in XML, to any remote DSP instance.

\subsection{OSGi}

OSGi \cite{osgi} is a generic platform for "dynamic module system for Java\texttrademark".
\cite{Mueller07} used OSGi as platform their sensor network.
In \cite{Baude07} OSGi is used to support large scale deployment. OSGi is flexible
enough to be used in mobile devices and in application servers. One aspect not addressed
by OSGi is distributed communication (although some extensions have
been proposed,e.g., \cite{Rellermeyer}). DSP was designed to handle remote communication and,
therefore, can complement OSGi capability. DSP Components are OSGi bundles (in fact, DSP itself
is a bundle) and can be remotely and dynamically maintained. OSGi capabilities along with DSP
design make well suitable for our project.

\section{NetBEAMS}
\label{SEC_NETBEAMS}

\begin{figure*} 
\centering
\epsfig{file=netbeams, width=14cm}
\caption{\label{FIG_NETBEAMS} NetBEAMS architecture.}
\end{figure*}

In the following we present a practical application of the DSP
introduced in the previous section. Our environmental sensor network
is dubbed NetBEAMS (Networked Bay Environmental Assessment Monitoring
System) and allows access to sensor equipment deployed throughout the
San Francisco Bay Area. This end-to-end system is a ready-to-use
turnkey solution that is adaptable to a wide variety of sensor types
and requires no programming expertise to operate. Configuration of the
system will be possible when the sensor is deployed in the field via a
web-based interface, eliminating the need for extra site visits by
technicians between service cycles to change systems functionalities
(e.g. sampling rate).  We present the NetBEAMS infrastructure by
discussing its hardware and software components.


\subsection{Hardware}

Figure \ref{FIG_NETBEAMS} provides an end-to-end overview of the
NetBEAMS architecture. NetBEAMS is built using multiple installations
of the DSP and by providing special purpose components for the various
tasks. One DSP installation is collocated with each sensor and an
additional DSP is running on the backend server. Because of the remote
locations where each individual sensor is deployed in the field and
the sparse density of the network, the resulting topology is a tree
structure of depth 1.

NetBEAMS supports an environmental sensor such as the YSI Sonde,
introduced in Section \ref{SEC_BACKGROUND}. In order to access its
sensor readings, we collocate it with an off-the-shelf embedded
computing platform called Gumstix \cite{gumstix01} (far left in Figure
\ref{FIG_NETBEAMS}).  The Gumstix is an ARM architecture and comes in
various hardware configurations.  A typical Gumstix configuration
consists of a motherboard and one or more expansion boards which
connect to the motherboard via on-board buses.  The motherboards draw
less than 250 mA @4V at 400 MHz and less than 50 mA while idling,
waiting for input.

The Gumstix runs Linux 2.6 with the BusyBox utilities, and uses the
OpenEmbedded cross-compile build environment to provide a complete
Linux environment and a large range of Linux applications for the ARM
architecture.  We use the JamVM \cite{jamvm01} implementation of Sun
Microsystem's virtual machine in order to run the DSP. The Gumstix
communicates with the YSI Sonde via an RS232 serial port using a
null-modem cable since both the Sonde and the Gumstix are DTE devices.
%The serial port configuration is:

%\begin{table}[!htb]
%\caption{\label{tab:RS232_Config}RS232 Serial Port Configuration}
%\centering
%\begin{tabular}{l l}
%\hline
%Baud Rate&9600\\
%Data Bit&8\\
%Parity&None\\
%Handshake&None\\
%\hline
%\end{tabular}
%\end{table}


%\begin{table}
%\caption{\label{TAB_RS232_Pinout}RS232 Serial Pinout}
%\centering
%\begin{tabular} {|l|l|l|}
%\hline
%Wire Color	&Pin Description        &DB-9\\ 
%\hline
%Yellow 		&RS232 TX    &2\\
%Orange		&RS232 RX    &3\\  
%Green  		&Alarm       &----\\ 
%Grey			&RTS         &----\\
%Blue  		&CTS         &----\\
%Red			&+ 12V DC    &9\\
%Black			&GND         &5\\  
%Purple		&SDI-12      &----\\ 
%Bare			&Shield      &----\\
%\hline
%\end{tabular}
%\end{table}
 

We make use of the cellular phone network to establish a communication
link with the backend server. The cellular phone network has the
advantages of reaching well beyond telemetry options such as wireless
networks and being a significantly lower cost solution than satellite
communications. We make use of the Huawei E220. The E220 is a USB
modem that supports HSDPA, UMTS, and EDGE packet data services at
maximum transmission rates of 3.6Mbps, 384kbps, and 236.8kbps
respectively.  HSDPA and UMTS operate at 2100MHz while GSM, GPRS, and
EDGE operate at 900, 1800, and 1900MHz. The modem connects to the
Gumstix motherboard via a mini USB interface (supporting USB 2.0).The
Gumstix communicates with the modem using the PPP protocol and
accesses the cellular network using a data plan from AT\&T.



\subsection{YSI Sonde Component}

Our implementation of the DSP is based on the Open Source
implementation of OSGi called Knopflerfish \cite{knopflerfish01}.
Since Sun Microsystems does not support its JDK for the Gumstix, we
use JamVM \cite{jamvm01} as the Java virtual machine implementation
and GNU Classpath \cite{classpath01} for the runtime libraries. We
have implemented various DSP Components that implement the
functionality needed for NetBEAMS. On the far left of Figure
\ref{FIG_NETBEAMS} is the actual sensor; in our case the
aforementioned YSI Sonde. The YSI Sonde DP (1) uses the RS232 standard
to read the physical measurements from the device over a serial port.
This component converts the physical measurements into a DSP-specific
message. Figure \ref{FIG_DSP_YSI_DATA} depicts the YSI Sonde's
specific message format which includes each measurement data point,
described in Table \ref{TAB_SONDE_MEASUREMENTS}.

\begin{figure}[!htb]
\centering
\epsfig{file=dsp-message-body-ysi, width=9cm}
\caption{\label{FIG_DSP_YSI_DATA} YSI message format.}
\end{figure}

The SondeDataContainerType defines the payload of messages generated
by the YSI Sonde DP. As all DSP messages, it is derived from the
AbstractMessageContent. The payload mainly consists of the
SondeDataType that defines all the sensor data that the YSI Sonde is
capable of producing. The YSI Sonde DP uses the RS232 to query the
physical device for its data in regular intervals. The measurements
are then converted into a DSP message and forwarded to the DSP Broker
from there they are forwarded to the remote communication component
described in the next section.  The YSI Sonde DP can also be
configured via special DSP messages, to direct the Sonde to change its
sampling frequency.  These property messages originate from a web
management interface (component (6) in Figure \ref{FIG_NETBEAMS}).


\subsection{Remote Communication}

All messages sent by the YSI Sonde DP need to be uploaded to a remote
database. Since the DSP itself can only handle communication within
its local DPs and DCs, we have created a matching pair of DC and DP
that can handle remote communication (components (2) and (3) in Figure
\ref{FIG_NETBEAMS}). As explained earlier, we make use of the cellular
phone network to upload sensor data to a remote backend server. While
the cellular phone network has sufficient coverage for more
environmental sensor networks, it is not cost effective to keep a data
link permanently open. The remote communiction components can be
configured to upload buffered sensor data only in certain time
intervals. Messages are transported via HTTP \cite{RFC2068}. The
matching DP/DC pair for remote communication has the following
properties:

\begin{itemize}
\item DSP Wire Transport Client: takes a collection of DSP messages
  and transmit them via HTTP. As a non-functional requirement, the
  interval in which this component will transmit messages to other
  components can be configured via the management interface.
\item DSP Wire Transport Server: is a HTTP server that receives the
  collection of DSP messages sent by the client, and piggy backs any
  messages destined for the remote client that may have queued up in
  the meantime.
\end{itemize}

The HTTP request and response are used to upload and download any
messages that have been queued at the respective end of the
communication link. The client and server component are capable of
buffering messages until they are sent to the remote destination
during the next communication cycle. Once messages have been
transported to their final destinations, they are unmarshalled and
passed on to the local DSP Broker for further dispatching. In this
regard the client and server are completely symmetrical. Messages are
dispatched with the help of the matcher to their final destinations.


\subsection{Web Management}

Web Interface. Management messages are regular
DSPMessages. Asynchronous UI: UI may only build up after next
communication cycle.

\section{Conclusions}
\label{SEC_CONCLUSION}

The California coastal region is populated by a vast number of
remotely deployed sensors that monitor environmental conditions
ranging from weather to water quality to ocean surface currents.
These sensors are operated by data providers, including resource
management groups, research scientists, municipalities, and state and
federal agencies, who could use near real-time data streams to inform
decision that impact public health, public safety, and the protection
of resources. Success of these efforts, whether small scale or a large
integrated network, depends on the first step in the data management
process: reliably obtaining data in near real-time from remotely
located sensors.  This step can be the weak link in the data
management pathway when telemetry options are unreliable.  The
availability of a plug-and-play computing platform designed to
communicate with a variety of sensor types would stabilize data
streams with poor telemetry and allowing expansion of sensor coverage
into regions not presently served.

In this paper we introduce a practical application of a sensor network
in the domain of environmental monitoring. We have built an
environmental sensor network in the San Francisco Bay using highly
specialized, off-the-shelf water quality sensors. The resulting
infrastructure enables near-realtime access to sensor data collected
from remote locations. Our end-to-end solution furthermore allows
configuration and management of remotely deployed sensors. The key to
our infrastructure is the DSP; a micro-kernel plug-and-play
architecure that can be configured flexibly to specific needs through
special purpose components. The NetBEAMS infrastructure as described
in the paper is available as Open Source and can be viewed in
operation at \texttt{www.netbeams.org}.

\bibliography{lit}
\bibliographystyle{plain}


\end{document}
