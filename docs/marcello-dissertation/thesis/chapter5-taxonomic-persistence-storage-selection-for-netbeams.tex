% main.tex, to be used with thesis.tex
% This contains the main work of your thesis.

%\bibliography{thesis}  % uses the references stored in Chapter1Radar.bib
\setcounter{table}{1}
\chapter{Empirical Analysis of Data Persistence Taxonomies for NetBEAMS}

Providing data persistence for an existing sensor network requires analysis of
the infrastructure and the nature of the data produced. Based on the
taxonomies of Chapter 3, and the requirements of a data persistence for
NetBEAMS in Chapter 4, this chapter aims at analyzing a group of database
technologies selected from the topics covered in Chapter 2.
Similarly, supported by the scope of the required implementation presented in
this chapter, the comparison of the technologies is summarized, highlighting
the selected database system used for the design of a component for NetBEAMS
and used for the design of the experiments.

\section{Scope of the use of the Technology}

The scope of the use of the database can involve different functional and
non-functional requirements defined in the last chapter. This work does not
intend to implement an application based on the database system selected, but
to provide the foundation of a database management system that can be used to
develop one focused less in refactoring and high scalability and performance.
For this reason, the use of the database system will be restricted to the data
persistence and use through a native system or through the use of native
programming languages or API. In this way, the scope of this technology
selection can be summarized as follows:

\begin{itemize}
  \item Provide data management over the collected sensor data, as a
  conventional database systems;
  \item Must be able to scale in any increases to the data load of
  the sensor network, as described in Chapter 2;
  \item  Must be able to use single or multiple servers to improve performance
  and optionally deal with Data-Centric approaches to sensor data partitioning;
  \item Must provide a data model that scales, decreasing the constant data
  schema changes.
\end{itemize}

\section{Database System ``Contenders''}

This section describes the database systems ``contenders'' considered to be used
as the persistence technology backend for NetBEAMS. As described in the
previous chapter, the selection of the technologies must be based on the list
of functional and non-functional requirements specified within the scope of
this work.

One of the essential questions related to data persistence is regarding the
data model and types of the database. That is, the use of the relational or
any other model to describe data along with its management. Traditionally, the
relational data model has been used to provide data persistence for different
types of projects, including sensor networks \cite{sn-dataware-house,
db-xml-enabled, sn-db-tinydb}. However, tradition does not always get
translated into efficiency in terms of problem solving. For this reason,
\cite{db-is-rdbs-dommed} reflects about the use of alternatives to the
relational model when the data persistence problem in consideration is to
provide data persistence for dynamic environments such as Internet applications.
The author also suggests that the relational model is hard to maintain in
ever-changing environments, and thus, proposes the use of the Key-Value-Pair
(KVP) data model and a different number of technologies. Similarly,
\cite{cloud-comp-survey} reports similar trends in academic and industrial
research in distributed computing using KVP databases in powerful systems
such as Cloud Computing \cite{cloud-comp-architectures}. For this reason, in
addition to the different database systems used by projects in the
literature review, this work also includes the review of a KVP database system
called mongoDB \cite{mongodb}, since it was among those cited in the surveys.
In such a manner, the list of the systems considered for assessment is the
following:

\begin{itemize}
  \item \textbf{MySQL}\cite{mysql}: an open-source relational database
  system popularized by the development of Internet applications, maintained
  by Sun Microsystems. \cite{sn-dataware-house} reports its use to develop a
  data warehouse for data collected from sensor devices using this technology;
  \item \textbf{TinyDB}\cite{tinydb}: developed and maintained by the Computer
  Science department of University of California, Berkeley, TinyDB is a
  relational database system specially developed for sensor devices. As
  referred in Section \ref{sec:sn-persitence-storage}, it is system used in
  many different sensor networks implementation such as \cite{sn-db-tinydb,
  sn-db-newop};
  \item \textbf{MongoDB}\cite{mongodb}: an open-source KVP database
  system suggested by different surveys to be an alternative to relational
  databases \cite{db-is-rdbs-dommed, cloud-comp-architectures}. It is maintained
  by 10Gen Incorporated;
  \item \textbf{DB2}\cite{db2}: in the pursuit of an XML database system, DB2
  is listed as a hybrid database system that offers both the relational and the
  XML models \cite{db-xml-enabled}. It is privately owned by IBM.
\end{itemize}

The following sections review these technologies' capabilities to adhere to
the specifications of the taxonomies defined in Chapter 3, as well as the
requirements and the scope for a data persistence of NetBEAMS, as defined in
Chapter 4.

\section{Analysis of the Purpose of Sensor Data}

The execution of the SF-BEAMS sensor network, together with the NetBEAMS
automated infrastructure, can be summarized as follows:

\begin{itemize}
  \item Data is generated by sensor devices, such as the YSI Sonde
  \cite{YSI-Sonde}, and manually collected by using a laptop to the data sink
  at the RTC laboratories;
  \item Upon data reception, the RTC staff index and archive the data for
  distribution using the OPeNDAP format;
  \item An automated approach to the data collection procedures is performed 
  using NetBEAMS \cite{netbeams2009}, using software components to obtain and
  send the data to the data sink node. A complete description of this approach
  is \cite{netbeams-dsp-architecture}.
\end{itemize}

The nature of data from NetBEAMS through SF-BEAMS is used for the purpose of
\textbf{Data Archival}. After the collected data captured from the sensors, it
requires further processing in order to be archived for later reuse. Different
types of users are expected to use the collected data, ranging from
researchers, students, and the public over the Internet.

\subsection{Technology Analysis}

Since all of developed database systems were implemented with the intention of
persisting data in long-term storage devices, every one listed provides
support for data persistence and management. Therefore, they are compliant to
the purpose of Data Archival for the sensor networks.

\section{Analysis of the Location of Sensor Data}
\label{sec:sn-data-location}

The advantages of the External Storage approach is the most common way to
implement persistence for any type of systems since data management is usually
offered by most database systems out-of-the-box. It is basically used to store
small volumes of data. On the other hand, the most common problems related to a
single External Data Storage approach are related to the capacity of the
device and operational problems. If the external storage device is situated in
the network, then the capacity of the device may be limited to receive
collected data from the sensors in the network, since it may run out of space.
Similarly, storage devices are very error prone and its hardware part may fail.

As shown in the previous chapter, NetBEAMS's architecture is based on sensor
network whose topology is a single-hop star with a centralized data sink. In
this way, all the collected data is transmitted to that single location as
described in Section \ref{sec:sn-infrastructure}. The simplest location to save
the collected data is through the use of at least an \textbf{External
Storage}. Similarly, the use of a Data-Centric Storage strategy is considered
in situations where the data sink is about to reach its storage capacity. The
\textbf{Data-Centric Storage} separates the collected data into dissimilar
locations, based on any property of the data. Therefore,
there are two different approaches to data partitioning:

\begin{itemize}
  \item \textbf{Horizontal Partitioning}: the data segmentation is implemented
  based on the values of the table rows, in the relational model point of view,
  or the collections elements, on KVP databases. That is, all the values defined
  by the columns are used in a given table physically located in specific
  servers. For instance, horizontal partitioning can be defined as a
  collection of five years worth of historical sensor data, partitioned into
  five separate servers. In this way, each server contains data related to
  each of the years;
  \item \textbf{Vertical Partitioning}: data is partitioned vertically in a way
  that the columns of an entity on the relational model are divided into
  different database tables. In this way, the particular dataset is broken
  down to different tables. For example, if the database is used to store
  pictures of a given sensor camera in a BLOB column, it would be the most
  preferable to the scenario where the images are not constantly referenced
  when compared to the textual data. Since KVP uses denormalized data, this
  partitioning strategy is not used.
\end{itemize}

\subsection{Advantages of the Data-Centric Approach}

The benefit of the Data-Centric approach can be directly associated with
database partitioning mechanisms described earlier. Since the collected data is
distributed into different locations, this approach decreases the size of
datasets when the database server performs a query processing in a database
table. For this reason, this approach helps the database administrators scale
their database infrastructure and improve the database performance.

The horizontal or vertical partitioning strategies are also referred to as
Database Sharding \cite{db-shard-discussion}, or simply Database partitioning
\cite{db-partitioning-relational}. Both the former and the latter are used in
regular schema-dependent models or schema-less models. Different approaches
worth mentioning:

\begin{itemize}
  \item \textbf{Hash Partitioning}: a hash key is computed based on
  different table columns of an entity \cite{db-shard-schemas,
  db-partitioning-relational}, providing an even distribution of the data;
  \item \textbf{Key Partitioning}: is based on the hash partitioning over the
  values of a specific key \cite{db-mongo-partition};
  \item \textbf{Range Partitioning}: the partition is based on specific ranges
  of the values of given a given column of a table. For instance, the collected
  data from the sensors could be separated by the year of its collection. For
  example, data collected in the year of 2009 would be stored in a different
  partition than the data collected in the year 2010
  \cite{db-partitioning-relational}.
\end{itemize}

An example of a data-centric storage with different partitions can be seen in
Figure \ref{fig:database-sharding-by-region}, where the collected data is
partitioned by its origin. Each shard is assumed to be placed in different
server hosts, as well as each of them uses the same ``denormalized'' data
models.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.5]{../diagrams/database-sharding-by-region}
  \caption{Example of Data-Centric Storage for Sensor Networks using Database
  Sharding}
  \label{fig:database-sharding-by-region}
\end{figure}

\subsection{Disadvantages of the Data-Centric Approach}

The data partitioning is a highly restricted technology, normally available to
advanced users of distributed database systems. Despite being offered as a
common-off-the-shelf functionality by some popular database systems, this
strategy requires closer database management and configuration. Some of the
problems related to this strategy are regarding its lifecycle management
\cite{db-shard-discussion}:

\begin{itemize}
  \item \textbf{Rebalancing Partitions}: considering a schema-dependent database
  system, changes on the schema of one shard requires rebalancing the
  collected data on each of the shards. As a consequence, the database shards
  transfers data to new locations whenever necessary. This technique is
  starting to appear as COTS implementations such as MySQL \cite{mysql} and
  mongoDB \cite{mongodb};
  \item \textbf{Referential integrity}: also considering a schema-dependent
  database system, any cross-shard query may run into the problem where
  references do not exist in other shards, since the application layer is
  responsible for enforcing data integrity. In this way, examples of such
  include verifying constraints of foreign keys when the partition is done
  using Vertical table partitioning, considering that data collections are
  organized in separate spaces, and physically placed in different shard nodes
  \cite{db-partitioning-relational}.
\end{itemize}

\subsection{Technology Analysis}

\begin{itemize}
  \item \textbf{MySQL}: Supports External or Data-Centric Storage approaches.
  When Data-Centric Storage is used, both vertical and horizontal partitions
  \cite{db-partitioning-relational} can be chosen, using different strategies
  to partition the data;
  \item \textbf{TinyDB}: Only supports the External Storage;
  \item \textbf{MongoDB}: Supports External or Data-Centric Storage. When the
  latter approach is used, the horizontal partition strategy is available with
  automatic shards \cite{db-mongo-partition};
  \item \textbf{DB2}: Supports External and Data-Centric storage. Only supports
  vertical table partition for the data-centric storage \cite{db-db2-partition}.
\end{itemize}

All the selected database systems support the External Storage method. However,
they all differ somewhat in terms of Data-Centric Storage support. Therefore,
MySQL and mongoDB are promising choices, with the difference of the use of the data model.

\section{Analysis of the Data Model}

One of the most common practices in the area of database system is to use the
relational model for data persistence, although the application of the system
may not fit to solve the problem. In fact, the main users of sensor networks may
not possess any expertise in database systems or data modeling, based on the
fact that they are from different science areas. \cite{sn-programming-language}
suggested the use of programming languages abstraction, instead of regular
database systems, to provide access to the collected data for both
technical and non-technical users. For instance, marine biologists manage
SF-BEAMS without expertise in data management or modeling systems. For this
reason, one of the requirements of the system is the use of a schema-less
approach, which describes the collected data without data modeling process
used in schema-dependent models. The \textbf{Key-Value-Pair Data Model} seems
to be an optional candidate that provides such a method of data design.

\subsection{Analysis of the Schema-Dependent Models}

Considering the inception of a relational data model \cite{relational-model}
and the use of the YSI Sonde data as the main entity in the system, Figure
\ref{fig:Relational-Model-Original} represents a prototype of the relational 
model, after passing through the process of normalization
\cite{db-normalization}.

\begin{figure}[!t]
  \centering
  \includegraphics[scale=0.65]{../diagrams/Relational-Model-Original}
  \caption{Relational Data Model for NetBEAMS - A first prototype}
  \label{fig:Relational-Model-Original}
\end{figure}

When a new type is added into the system, the refactored version of the
relational model be depicted in Figure
\ref{fig:Relational-Model-Addition-Modified}. Some observations are considered
in this scenario:

\begin{figure}[!b]
  \centering
  \includegraphics[scale=0.6]{../diagrams/Relational-Model-Addition-Modified}
  \caption{Relational Data Model for NetBEAMS - Modified version with new
  entity}
  \label{fig:Relational-Model-Addition-Modified}
\end{figure}

\begin{itemize}
  \item Data schema that constantly change requires continuous database
  normalization processes, changes to structure, database management, and all
  the code that uses the data. Schema-Dependent databases always require
  refactoring of the schema to accommodate changes to the entities' properties;
  \item \cite{sn-provenance} describes the relational model as problematic 
  when describing collected data from sensor devices;
  \item \cite{sn-db-newop} suggests changes to the SQL clauses of TinyDB to
  better support time-series, an important property when describing
  collected data from with spatial-temporal properties.
\end{itemize}

Other projects have used the XML data models for persistence. It falls
into the same category as the Relational Model using XML documents \cite{xml},
since XML documents must fulfill the specifications defined by an XML Schema
\cite{xml-schema}. This model uses XPath \cite{xml-xpath} technology for
querying documents, although some hybrid \cite{db2} technologies may still use
SQL \cite{sql} for that matter. In this way, the view of an example of database
state for the defined previous schema can be seen in Figure
\ref{fig:persistence-example-relational}.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.7]{../diagrams/persistence-example-relational}
  \caption{Instance of a Relational Model Database Prototype}
  \label{fig:persistence-example-relational}
\end{figure}

This data model has been used to solve data models for different types of
application. One such a problem is the one to represent entities by a list of
properties with keys and relating values, called Key-Value data model
\cite{db-kvp-in-relational01, db-kvp-in-relational02}. The author of
\cite{db-kvp-in-relational01} suggests that this is used as a technique used
when the addition of number of properties of an entity constantly changes, and
thus, requires constant refactoring of the relational data model. Considering
this data model for sensor network devices, whose properties are lists of keys
and relating values, an ``one-fits-all'' attempt to use the KVP data model
using the relational data model is depicted in Figure
\ref{fig:KVP-on-Relational-Model}, and a given example of the state of a
database using this schema in Figure
\ref{fig:persistence-example-relational-kvp}.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.6]{../diagrams/KVP-on-Relational-Model}
  \caption{KVP Data Model implementation using Relational Model}
  \label{fig:KVP-on-Relational-Model}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.75]{../diagrams/persistence-example-relational-kvp}
  \caption{KVP over Relational Model Database Prototype}
  \label{fig:persistence-example-relational-kvp}
\end{figure}

\newpage

\subsection{Analysis of the Schema-less Models}

The growth of distributed systems and the Internet have enabled the development
of powerful database servers that can be organized in the context of
infrastructure and how to represent models. A powerful up-coming approach is
the use of database systems that do not use structured language for querying
its data. One such example is called Key-Value Pair (KVP) data model
\cite{db-kvp}, and it is characterized as follows:

\begin{itemize}
  \item data is structured in collections of key-value pairs, as it is done in
  hash data structure. The definition of the key is a given property with its
  associating value;
  \item the query process is using mechanics similar to programming or
  scripting language, that is, the use of APIs in a given programming language.
\end{itemize}

There are no records of the use of this data model with sensor networks. Data
is generally aggregated by given entities and any needed property applied to
it. Key may be composed by embedded keys having a dynamic structure and freely
used without a schema validation mechanism as used schema-dependent data
models, having the following organization:

\begin{itemize}
  \item entities from the same domains are placed into a ``bucket'';
  \item entities have a set of attributes and relating values;
  \item entities with different set of attributes may be contained in the same
  bucket, since there is no schema to govern the bucket items restriction.
\end{itemize}

For instance, all data needed for the YSI Sonde Data, as well as all necessary
provenance data and annotation as defined in Section
\ref{sec:sn-data-description}, are represented by means of key-value pairs as
seen in Figure \ref{fig:persistence-example-kvp}.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.5]{../diagrams/persistence-example-kvp}
  \caption{KVP Database instance Prototype}
  \label{fig:persistence-example-kvp}
\end{figure}

\subsection{Technology Analysis}

The properties of the relational and key-value data models were compared by
\cite{db-is-rdbs-dommed} and summarized in Table 5.1:

\begin{table}[!b]
    \label{tab:properties-schema-vs-schemaless}
    \caption{Schema-Dependent X Schema-less Databases Compared: Properties}
    \begin{center}
    \begin{tabular}{|p{210pt}|p{210pt}|}\hline
    Schema-Dependent Databases & Schema-less Databases\\\hline
    \begin{enumerate}
      \item Real-world model represented by entities, classified in tables;
      \item Tables composed by columns and rows. Rows are comprised by column
      values, which have the same schema;
      \item Data Model is defined in advance with a schema, which contains
      relationships and constraints to enforce data integrity;
      \item Data represents ``natural'' entities, not application specific;
      \item Data Normalization is the data structuring process to remove data
      duplication, as well as establishing data associations through table
      relationships \cite{db-normalization};
      \item Data Provenance can be provided through data types such as
      ``timestamp'' for time or float for the GPS float-based coordinates; 
    \end{enumerate} 
    & 
    \begin{enumerate}
      \item Real-world model by entities, classified in Domains;
      \item Domains are similar to tables, but like buckets that contains items
      without a pre-defined schema, what enables them to have different schemas;
      \item Items are identified by keys, as well as have a dynamic set of
      attributes attached to it, however with no schema defined;
      \item Items may represent not only the natural representation of data, but
      also include application-specific data;
      \item Since data may be repeated, no data normalization is done, so that
      integrity is done in the application layer;
      \item Data provenance can be added through the use of keys and relating
      values for the time information and location of the data.
    \end{enumerate}
    \\\hline
    \end{tabular}
    \end{center}
\end{table}

\newpage

In order to have access to the persisted data, both types of data models
support methods: one via structured languages, and the other via abstractions
of programming languages. \cite{db-is-rdbs-dommed} summarizes the differences
shown in Table 5.2:

\begin{table}[!h]
    \label{tab:daccess-schema-vs-schemaless}
    \caption{Schema-Dependent X Schema-less Databases: Data Access}
    \begin{center}
    \begin{tabular}{|p{210pt}|p{210pt}|}\hline
    Schema-Dependent Databases & Schema-less Databases\\\hline
    \begin{enumerate}
      \item The basic CRUD (Create-Retrieve-Update-Delete)
      database operations are performed using a structured language such
      as the SQL or XPath;
      \item Query languages can access data from different tables through
      joins, containing aggregation functions to apply on the returned values.
    \end{enumerate} 
    & 
    \begin{enumerate}
      \item The CRUD operations are performed via an abstraction of
      programming language. (E.g. ``db.collection.find()'',
      ``db.collection.insert()'');
      \item Some technologies provide basic SQL-like syntax for filter criteria
      with some predicates like equals to (=), different than (!=), less than
      or equals ($\leq$), greater than or equals ($\geq$), among others;
      \item The data and application integrity logic is placed in the
      application layer.
    \end{enumerate}
    \\\hline
    \end{tabular}
    \end{center}
\end{table}

Finally, each data model provides its own APIs to the integration with external
systems. \cite{db-is-rdbs-dommed} differentiates each of the application interfaces
provided by each of them, as summarized on table 5.3.

\begin{table}[!h]
    \label{tab:api-interface-schema-vs-schemaless}
    \caption{Schema-Dependent X Schema-less Databases: Application Interface}
    \begin{center}
    \begin{tabular}{|p{210pt}|p{210pt}|}\hline
    Schema-Dependent Databases & Schema-less Databases\\\hline
    \begin{enumerate}
      \item Have their own specific API or through ODBC (Open Database
      Connectivity);
      \item Data is stored in a format that represents its natural structure,
      and for this reason, in a single or distributed fashion.
    \end{enumerate} 
    & 
    \begin{enumerate}
      \item Tend to provide Web Services Interfaces such as the REST
      \cite{http-rest};
      \item \cite{db-is-rdbs-dommed} claims that data is stored in a more
      effective way, requiring only code plumbing for the relational code;
    \end{enumerate}
    \\\hline
    \end{tabular}
    \end{center}
\end{table}

The data model used by each of the selected database systems can be summarized
as follows:

\begin{itemize}
  \item \textbf{MySQL}: uses the Relational Data Model with the use of SQL;
  \item \textbf{TinyDB}: uses the Relational Data Mode with the use of SQL; 
  \item \textbf{MongoDB}: uses Key-Value Pair Data Model with an abstraction of 
  programming language functions calls;
  \item \textbf{IBM DB2}: uses the Relational and Structured models with SQL
  and XPath, respectively.
\end{itemize}

\section{Analysis of the Data Description}

\textbf{Data Description} is the method used to describe the collected data
from sensors, especially those produced by real-time data streams. Since that
type of data does not include descriptions of its values, data provenance
offers guidelines to improve the description of the collected data.

In addition to data provenance, annotation is another technique used to
better describe the collected data from sensor devices. Its main purpose is to
provide a means of identifying observations, creating indexes based on simple
keywords. For an environmental sensor network, this is invaluable used to
better manage the collected data.

\subsection{Use of Provenance-Aware Data}

The inclusion of provenance data into the collected data enriches the
description of a given event, and is always useful to determine different
aspects of the data. As mentioned in Chapter 3, data provenance helps identify
the nature of the data by the identification of the properties of a given
sensor device, for example. Similarly, provenance adds spatial-time data in
order to correlate the observed data with time a given location and time of
occurrence.

Although metadata gives more information about the data, it just
represents additional data inserted together with the raw data collected
from the sensor devices may contribute with a decreasing amount of disk
storage. Therefore, the use of provenance-away data increases the required
disk space used to save the collected data from sensor devices.

\subsection{Use of Annotations}

Annotations are used to describe the collect data even more, since the
additional ``observation'' of the data are being stored together with the data.
For example, the use of tags to a given entity may help identifying and different
observations regarding the data collected from sensor devices. As shown in
Figure \ref{fig:persistence-example-kvp}, the addition of the key ``tag'' was
used to describe the observations that happened when the event of ``oil spill''
occurred. In this way, tags can be indexed for better search of the collected
data.

On the other hand, the use of annotations behaves the same as the use of
Provenance data. It will require additional disk space to store the
collected data from sensors.

\subsection{Technology Analysis}

All the database systems technology supports the use of Data Provenance or
Annotations. The Key-Value Pair data model has the advantage of not maintaining
a schema design, and therefore, additional keys of descriptions can be added at
any time without requiring schema changes. On the other hand, the relational
data model requires schema changes to support the addition a new table column.

\begin{itemize}
  \item \textbf{MySQL}: supports data provenance and annotations via column
  types on the entities, requiring schema changes;
  \item \textbf{TinyDB}: supports data provenance and annotations via column
  types on the entities, requiring schema changes. Different projects have
  suggested changes to the SQL language used to give better support to
  spatial-temporal data \cite{sn-db-newop}.
  \item \textbf{MongoDB}: supports both data provenance and annotations with
  the definition of a new key on a given collection. No changes are required to
  the addition of the keys;
  \item \textbf{IBM DB2}: supports data provenance and annotations via column
  types on the entities, requiring schema changes.
\end{itemize}

\section{Analysis of the Query Processing Mechanism}

As a direct result from the previous section, the use of \textbf{Centralized Query
Processing} is indicated for NetBEAMS, because the SF-BEAMS data goes directly
to the individual network sink and, therefore, a centralized point of the data.

An advantage of centralized data management and query processing is simpler
than the in-network query method. Data is verified by a straightforward
database management system without the risk of data being unavailable, when
the data is spread among the network nodes. On the other hand, when the
Centralized Query processing is used, problems may occur. Depending on the
size of the datasets and the database technology, performance may be a concern
due to the alleged Funneling Affect \cite{sn-storage04}, since the
point-of-traffic is concentrated in the centralized system.

In order to mitigate the problems originated by this query processing
mechanism, techniques such as Data Replication can be used.

\subsection{Technology Analysis}

All the database systems technology support a centralized query system. In
addition to that, they can be sorted into different distributed nodes when
used in a partitioned environment.

\section{Analysis of the System Organization}

Sensor Network data can be saved into database system that are organized
by either a Centralized or Distributed System. While a centralized database
system may be considered to be easier to manage, it may fail to adjust to
changes of requirements to manage data. On the other hand, a distributed
database system can be used to implement a data-centric solution. Therefore, a
database system that can be organized in both approaches is a good candidate to
be used a data persistence technology for sensor networks.

Distributed Systems can improve the performance of data management by providing
techniques for parallel data processing such as Map Reduce \cite{map-reduce,
bigtable}. It also helps decreasing the system load and bottleneck problems
related data creation and retrieval. It is also seen as an optional mechanism
of reducing the funneling effect of a centralized system by directing queries
to a given data partition \cite{sn-storage04}. Data Replication
\cite{data-replication} provides a way to decentralize data access by
providing duplicated data that is intended to be used on reading operations.

Although a distributed system may provide better support to the problem being
solved, it may be a difficult solution to propose. Since it is designed as set
of cooperating subsystems, multiple points of failure exist in this type of
system, making it difficult to be operated. Furthermore, it requires more
technical knowledge expertise to manage the different systems that composed a
distributed database management system.

\subsection{Technology Analysis}

\begin{itemize}
  \item \textbf{MySQL}: provides support to data replication;
  \item \textbf{TinyDB}: it does not provide support to data replication;
  \item \textbf{MongoDB}: supports data replication;
  \item \textbf{IBM DB2}: supports data replication.
\end{itemize}

\section{Other Non-Functional Analysis}

Other non-functional requirements to be considered are related to the
functionalities and type of database systems.

\begin{itemize}
  \item \textbf{Open-Source}: Given the nature of the project, the
  technology to be used must be free of charge \cite{open-source}, that is, no
  costs involved in the adoption a such technology; along with the support from
  the community;
  \item \textbf{Native APIs}: In order to consider the scope of this work
  defined in the last chapter, the solution for persisting collected sensor
  data must be not only limited to a technology that provides data access, such
  as SQL, but also by other data access mechanisms \textbf{data access
  mechanisms};
  \item \textbf{Export Feature}: the technology must support export
  capabilities during its execution such as hot backps.
\end{itemize}

\subsection{Technology Analysis}

Most of the technologies listed provides access to the data sets through the
use of drivers in different programming and scripting languages such as Java,
Python, Perl, among others.

\begin{itemize}
  \item \textbf{MySQL}: Is  open-source, supports hot backup and contains
  scripting APIs from  the community;
  from the community. Also APIs are available for the majority of languages;
  \item \textbf{TinyDB}: Not open-source nor does it support hot backup;
  \item \textbf{MongoDB}: An open-source database system with an increasing
  support from  the community, offering native APIs in different programming
  languages and scripting languages;
  \item \textbf{IBM DB2}: Not open-source, but offers support from its
  community.
\end{itemize}

Only MySQL and mongoDB supports the non-functional requirements defined in this
section.

\section{Global Analysis Results and Technology Selection}

Each of the databases selected was scored according to the support provided to
the different types of taxonomies and requirements defined for a selection of a
persistence technology for NetBEAMS. Table 5.4 summarizes these scores using
the (+) and (-) notation. Since they all provide support to data archival for
a small volume of data, these parameters are not included in the table.

\begin{table}[!b] 
    \label{tab:technology-selection}
    \caption{Technologies Selection Scoring}
    \begin{center}
        \begin{tabular}{|c|c|c|c|c|c|c|}\hline 
        \textbf{Database} & \textbf{MySQL} & \textbf{TinyDB} & \textbf{MongoDB} & \textbf{IBM DB2}\\\hline
        Centralized Query & + & + & + & + \\\hline 
        Schema-less & - & - & + & -\\\hline 
        Non-Structure Query & - & - & + & -\\\hline 
        Provenance Support & + & + & + & +\\\hline 
        Distributed System & + & - & + & +\\\hline 
        Data Partition & + & - & + & +\\\hline 
        Export Capabilities & + & - & + & -\\\hline 
        Native APIs & + & + & + & +\\\hline
        Open-Source & + & + & + & -\\\hline
        \end{tabular}
    \end{center}
\end{table}

In general, all the selected databases can be used for the purpose of data
storage, also associated with the location of the collected data being in an
external storage. Since the data volume produced by NetBEAMS is small, a
typical centralized server can be used to provide management of a database
management system, and consequently a centralized query mechanism. Additionally,
a distributed system can also be used in the case of future system expansion.
All technologies, but TinyDB, fit to these requirements.

As used in different projects, schema-dependent models such as the relational
data model can be used to design the collected data entities. As shown
in Figure \ref{fig:persistence-example-relational}, the specification of a
schema for the YSI Sonde Data is achieved. However, what if a new sensor device
needs to be included into the model? A refactoring would be necessary to
accommodate this new requirement. All database presented technologies, but
mongoDB, use the relational model.

Considering the nature of sensor devices as a list of properties, where the
collected data values are labeled and represented by keys, the Key-Value Pair
data model is proposed in Figure \ref{fig:persistence-example-relational-kvp}.
Considering that this technique can support any different device with
different properties, this would be a good candidate to be used as a
persistence model to support any properties list of any sensor device.
However, this approach results in different problems. Taking into account the
support to data provenance, the use of time-series for the solution results in
data repetition, as shown in the values of the column ``time''. Thus, it
represents an insertion anomaly on the First Normal Form of the relational model
\cite{relational-model}, where the collected data metadata must be repeated.
Furthermore, \cite{db-kvp-in-relational02} describes that the use of this
strategy in regular relational databases as one that presents poor retrieval
performance, due to the concentration of data in a single database table.
Therefore, this strategy is not well suited to provide persistence for data
collected from sensor networks, described by the guidelines of Data Provenance.

Although the use of schema-less database systems in sensor networks has not been
reported by the literature review, the schema-less data model can be used as
opposed to the schema-dependent because it does not require the definition of a
static schema. As shown in Figure \ref{fig:persistence-example-kvp}, different
instances of the YSI Sensor are represented not only by the properties of the
sensor device, but also by data provenance and annotations. Data provenance is
prepresented by the keys ``time, ``latitude'' and ``longitude'', while
Annotations by the key ``tag''. Furthermore, since the the method of data
access of the KVP databases is through the use of an abstraction of programming
languages, it may also offer a better support to non-skilled users such as the
RTC marine biologists. mongoDB is the only technology that provides such
support.

All the discussed tools provide access to data through an additional API, but
mongoDB also provides it as a query method. Without no reason to further
discussions, mongoDB was considered as a good candidate to be explored as a
data persistence solution for NetBEAMS. Moreover, it also provides all the
other requirements as a technology as such being an open-source application and
that it can be used as a single server or a distributed system, requirement
necessary to develop a Data-Centric.

To conclude, this chapter evaluated different database systems filtered
from Chapter 2. After presenting the database system ``contenders'', the
analysis of each of the taxonomies was conducted for each of the technologies,
culminating with the technology selection comparison. The following chapter
describes the design of the solution using mongoDB as the primary solution for
the backend.